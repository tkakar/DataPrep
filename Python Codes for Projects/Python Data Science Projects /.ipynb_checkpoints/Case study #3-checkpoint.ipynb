{
 "metadata": {
  "name": "",
  "signature": "sha256:7fa2dc90441d96230e62626a87c0cf7a526e9cfda327a77689b7818fdcace29c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Case Study 3 : Textual analysis of movie reviews\n",
      "** Due Date: October 26, 11:59PM for Tuesday/Friday Section**\n",
      "\n",
      "** Due Date: November 10, 5:30PM for Monday Section**\n",
      "\n",
      "*------------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**TEAM Members:** Please EDIT this cell and add the names of all the team members in your team\n",
      "\n",
      "    Chong Zhou (Andy)\n",
      "    \n",
      "    Diana Batista\n",
      "    \n",
      "    Marcus Moyses\n",
      "    \n",
      "    Tabassum Kakar"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Desired outcome of the case study.**\n",
      "* In this case study we will look at movie reviews from the v2.0 polarity dataset comes from\n",
      "the http://www.cs.cornell.edu/people/pabo/movie-review-data.\n",
      "    * It contains written reviews of movies divided into positive and negative reviews.\n",
      "* As in Case Study 2 idea is to *analyze* the data set, make *conjectures*, support or refute those conjectures with *data*, and *tell a story* about the data!\n",
      "    \n",
      "**Required Readings:** \n",
      "* This case study will be based upon the scikit-learn Python library\n",
      "* We will build upon the turtorial \"Working With Text Data\" which can be found at http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
      "\n",
      "**Case study assumptions:**\n",
      "* You have access to a python installation\n",
      "\n",
      "**Required Python libraries:**\n",
      "* Numpy (www.numpy.org) (should already be installed from Case Study 2)\n",
      "* Matplotlib (matplotlib.org) (should already be installed from Case Study 2)\n",
      "* Scikit-learn (scikit-learn.org) (installation instructions can be found on the web page)\n",
      "\n",
      "** NOTE **\n",
      "* Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost.\n",
      "\n",
      "*----------------------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Problem 1: Complete Exercise 2: Sentiment Analysis on movie reviews from http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Assuming that you have downloaded the scikit-learn source code:\n",
      "    * The data cane be downloaded using doc/tutorial/text_analytics/data/movie_reviews/fetch_data.py\n",
      "    * A skeleton for the solution can be found in doc/tutorial/text_analytics/skeletons/exercise_02_sentiment.py\n",
      "    * A completed solution can be found in doc/tutorial/text_analytics/solutions/exercise_02_sentiment.py\n",
      "* **It is ok to use the solution provided in the scikit-learn distribution as a starting place for your work.**\n",
      "\n",
      "##Modify the solution to Exercise 2 so that it can run in this iPython notebook\n",
      "* This will likely involved moving around data files and/or small modifications to the script."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import tarfile\n",
      "try:\n",
      "    from urllib import urlopen\n",
      "except ImportError:\n",
      "    from urllib.request import urlopen\n",
      "\n",
      "URL = ('http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz')\n",
      "\n",
      "ARCHIVE_NAME = URL.rsplit('/', 1)[1]\n",
      "DATA_FOLDER = 'txt_sentoken'\n",
      "\n",
      "if not os.path.exists(DATA_FOLDER):\n",
      "\n",
      "    if not os.path.exists(ARCHIVE_NAME):\n",
      "        print('Downloading dataset from %s (3 MB)' % URL)\n",
      "        opener = urlopen(URL)\n",
      "        open(ARCHIVE_NAME, 'wb').write(opener.read())\n",
      "\n",
      "    print('Decompressing %s' % ARCHIVE_NAME)\n",
      "    tarfile.open(ARCHIVE_NAME, \"r:gz\").extractall(path='.')\n",
      "    os.remove(ARCHIVE_NAME)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Downloading dataset from http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz (3 MB)\n",
        "Decompressing review_polarity.tar.gz"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.datasets import load_files\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn import metrics\n",
      "\n",
      "movie_reviews_data_folder = 'txt_sentoken'\n",
      "dataset = load_files(movie_reviews_data_folder, shuffle=False)\n",
      "print('n_samples: %d' % len(dataset.data))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "n_samples: 2000\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split the dataset in training and test set:\n",
      "docs_train, docs_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.25, random_state=None)\n",
      "\n",
      "# Build a vectorizer / classifier pipeline that filters out tokens\n",
      "# that are too rare or too frequent\n",
      "pipeline = Pipeline([\n",
      "  ('vect', TfidfVectorizer(min_df=3, max_df=0.95, ngram_range=(1, 1))),\n",
      "  ('clf', LinearSVC(C=1000))\n",
      "])\n",
      "\n",
      "# Fit the pipeline on the training set using grid search for the parameters\n",
      "parameters = {}\n",
      "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
      "grid_search.fit(docs_train, y_train)\n",
      "\n",
      "# print the cross-validated scores for the each parameters set\n",
      "# explored by the grid search\n",
      "print(grid_search.grid_scores_)\n",
      "\n",
      "# Predict the outcome on the testing set and store it in a variable\n",
      "# named y_predicted\n",
      "y_predicted = grid_search.predict(docs_test)\n",
      "\n",
      "# Print the classification report\n",
      "print(metrics.classification_report(y_test, y_predicted, target_names=dataset.target_names))\n",
      "\n",
      "# Print and plot the confusion matrix\n",
      "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
      "print(cm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[mean: 0.81467, std: 0.01210, params: {}]\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        neg       0.86      0.85      0.85       260\n",
        "        pos       0.84      0.85      0.84       240\n",
        "\n",
        "avg / total       0.85      0.85      0.85       500\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[221  39]\n",
        " [ 36 204]]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Problem 2: Explore the scikit-learn TfidVectorizer class\n",
      "\n",
      "**Read the documentation for the TfidVectorizer class at http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html.** \n",
      "* Define the term frequency\u2013inverse document frequency (TF-IDF) statistic (http://en.wikipedia.org/wiki/Tf%E2%80%93idf will likely help).\n",
      "* Run the TfidVectorizer class on the training data above (docs_train).\n",
      "* Explore the min_df and max_df parameters of TfidVectorizer.  What do they mean? How do they change the features you get?\n",
      "* Explore the ngram_range parameter of TfidVectorizer.  What does it mean? How does it change the features you get? (Note, large values  of ngram_range may take a long time to run!)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#TF-IDF:\n",
      "A measure of how relevant a word is to a document in a collection of documents. The TF-IDF statistic of a word gets bigger as the word appears more often inside a document, but is penalized by how common the word is considering the entire collection of documents."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#min_df and max_df:\n",
      "The parameters min_df and max_df control the threshold of the term frequencies included in the analysis. The values used in problem 1 (min_df=3 and max_df=0.95) mean that for a word to be considered in the analysis it should appear at least 3 times in the document and at most in 95% of the documents in the collection.\n",
      "\n",
      "By changing these 2 parameters we essentially modify the number of features available to create our classification model. The lower the threshold for min_df the more words you consider for analysis as you start to include very uncommon words. Similarly the higher the threshold for max_df the more words are included for analysis as you start to include very common words. A balance must be found when setting these parameters as we definitely don't want to include words that are very common like prepositions, connective words, etc. and we don't want to exclude some adjetives that are uncommon but are really aligned with the sentiment of the text such as awful, adorable, etc."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Build a vectorizer / classifier pipeline that filters out tokens\n",
      "# that are too rare or too frequent\n",
      "pipeline = Pipeline([\n",
      "  ('vect', TfidfVectorizer(ngram_range=(1, 1))),\n",
      "  ('clf', LinearSVC(C=1000))\n",
      "])\n",
      "\n",
      "# Build a grid search to find out best min_df and max_df.\n",
      "# Fit the pipeline on the training set using grid search for the parameters\n",
      "parameters = { \n",
      "    'vect__min_df': range(1, 5),\n",
      "    'vect__max_df': [0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95]\n",
      "}\n",
      "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
      "grid_search.fit(docs_train, y_train)\n",
      "\n",
      "print 'Best parameters for TfidfVectorizer:'\n",
      "best_parameters, score, _ = max(grid_search.grid_scores_, key=lambda x: x[1])\n",
      "for param_name in sorted(parameters.keys()):\n",
      "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
      "print\n",
      "\n",
      "# Predict the outcome on the testing set and store it in a variable\n",
      "# named y_predicted\n",
      "y_predicted = grid_search.predict(docs_test)\n",
      "\n",
      "# Print the classification report\n",
      "print(metrics.classification_report(y_test, y_predicted, target_names=dataset.target_names))\n",
      "\n",
      "# Print and plot the confusion matrix\n",
      "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
      "print(cm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best parameters for TfidfVectorizer:\n",
        "vect__max_df: 0.86\n",
        "vect__min_df: 2\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        neg       0.86      0.85      0.86       260\n",
        "        pos       0.84      0.85      0.85       240\n",
        "\n",
        "avg / total       0.85      0.85      0.85       500\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[221  39]\n",
        " [ 35 205]]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#ngram-range:\n",
      "This parameter sets the range of combined words that are used as a feature. This is necessary because for some words we need the context to correctly mark it a positive or negative meaning. For instance the \"good\" has generally a positive meaning but if it preceeded by the word \"not\" then it has a negative meaning.\n",
      "Using a ngram-range of (1,2) helps in this case as we would consider \"not good\" as a feature also and not just \"good\"."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Build a vectorizer / classifier pipeline that filters out tokens\n",
      "# that are too rare or too frequent\n",
      "pipeline = Pipeline([\n",
      "  ('vect', TfidfVectorizer(min_df=2, max_df=0.86)),\n",
      "  ('clf', LinearSVC(C=1000))\n",
      "])\n",
      "\n",
      "# Build a grid search to find out best value for ngram range.\n",
      "# Fit the pipeline on the training set using grid search for the parameters\n",
      "parameters = { 'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)] }\n",
      "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
      "grid_search.fit(docs_train, y_train)\n",
      "\n",
      "print 'Best parameters for TfidfVectorizer:'\n",
      "best_parameters, score, _ = max(grid_search.grid_scores_, key=lambda x: x[1])\n",
      "for param_name in sorted(parameters.keys()):\n",
      "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
      "print\n",
      "\n",
      "# Predict the outcome on the testing set and store it in a variable\n",
      "# named y_predicted\n",
      "y_predicted = grid_search.predict(docs_test)\n",
      "\n",
      "# Print the classification report\n",
      "print(metrics.classification_report(y_test, y_predicted, target_names=dataset.target_names))\n",
      "\n",
      "# Print and plot the confusion matrix\n",
      "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
      "print(cm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best parameters for TfidfVectorizer:\n",
        "vect__ngram_range: (1, 3)\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        neg       0.88      0.82      0.85       260\n",
        "        pos       0.81      0.88      0.85       240\n",
        "\n",
        "avg / total       0.85      0.85      0.85       500\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[212  48]\n",
        " [ 29 211]]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*------------------------\n",
      "\n",
      "#Problem 3: Machine learning algorithms\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Based upon Problem 2 pick some parameters for TfidfVectorizer\n",
      "    * \"fit\" your TfidfVectorizer using docs_test\n",
      "    * Compute \"Xtrain\", a Tf-idf-weighted document-term matrix using the transform function on docs_test \n",
      "    * Compute \"Xtest\", a Tf-idf-weighted document-term matrix using the transform function on docs_train\n",
      "    * Note, be sure to use the same Tf-idf-weighted class (**\"fit\" using docs_test**) to transform **both** docs_test and docs_train\n",
      "* Examine two classifiers provided by scikit-learn \n",
      "    * LinearSVC\n",
      "    * KNeighborsClassifier\n",
      "    * Try a number of different parameter settings for each and judge your performance using a confusion matrix (see Problem 1 for an example).\n",
      "* Does one classifier, or one set of parameters work better?\n",
      "    * Why do you think it might be working better?\n",
      "* For a particular choice of parameters and classifier, look at 2 examples where the prediction was incorrect.\n",
      "    * Can you conjecture on why the classifier made a mistake for this prediction?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Build a vectorizer / classifier pipeline that filters out tokens\n",
      "# that are too rare or too frequent\n",
      "tfidf_vectorizer = TfidfVectorizer(min_df=2, max_df=0.86, ngram_range=(1, 3))\n",
      "\n",
      "# train on docs_test and build XTrain and XTest\n",
      "XTrain = tfidf_vectorizer.fit_transform(docs_test)\n",
      "XTest = tfidf_vectorizer.transform(docs_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use LinearSVC to predict classes\n",
      "classifier = LinearSVC()\n",
      "\n",
      "pipeline = Pipeline([\n",
      "  ('clf', classifier)\n",
      "])\n",
      "\n",
      "# Build a grid search to find out the best parameters\n",
      "# Fit the pipeline on the training set using grid search for the parameters\n",
      "parameters = { 'clf__C': range(1, 16000, 1000) }\n",
      "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
      "grid_search.fit(XTrain, y_test)\n",
      "\n",
      "print 'Best parameters for LinearSVC:'\n",
      "best_parameters, score, _ = max(grid_search.grid_scores_, key=lambda x: x[1])\n",
      "for param_name in sorted(parameters.keys()):\n",
      "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
      "print\n",
      "\n",
      "#classifier.fit(XTrain, y_test)\n",
      "y_predicted = grid_search.predict(XTest)\n",
      "\n",
      "# Print the classification report\n",
      "print(metrics.classification_report(y_train, y_predicted, target_names=dataset.target_names))\n",
      "\n",
      "# Print and plot the confusion matrix\n",
      "cm = metrics.confusion_matrix(y_train, y_predicted)\n",
      "print(cm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best parameters for LinearSVC:\n",
        "clf__C: 1001\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        neg       0.79      0.82      0.81       740\n",
        "        pos       0.82      0.78      0.80       760\n",
        "\n",
        "avg / total       0.80      0.80      0.80      1500\n",
        "\n",
        "[[610 130]\n",
        " [164 596]]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use KNN to predict classes\n",
      "classifier = KNeighborsClassifier()\n",
      "\n",
      "pipeline = Pipeline([\n",
      "  ('clf', classifier)\n",
      "])\n",
      "\n",
      "# Build a grid search to find out the best parameters\n",
      "# Fit the pipeline on the training set using grid search for the parameters\n",
      "parameters = { \n",
      "    'clf__n_neighbors': range(1, 15),\n",
      "    'clf__weights': ('uniform', 'distance')\n",
      "}\n",
      "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
      "grid_search.fit(XTrain, y_test)\n",
      "\n",
      "print 'Best parameters for KNN:'\n",
      "best_parameters, score, _ = max(grid_search.grid_scores_, key=lambda x: x[1])\n",
      "for param_name in sorted(parameters.keys()):\n",
      "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
      "print\n",
      "\n",
      "#classifier.fit(XTrain, y_test)\n",
      "y_predicted = grid_search.predict(XTest)\n",
      "\n",
      "# Print the classification report\n",
      "print(metrics.classification_report(y_train, y_predicted, target_names=dataset.target_names))\n",
      "\n",
      "# Print and plot the confusion matrix\n",
      "cm = metrics.confusion_matrix(y_train, y_predicted)\n",
      "print(cm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best parameters for KNN:\n",
        "clf__n_neighbors: 12\n",
        "clf__weights: 'distance'\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "        neg       0.65      0.75      0.69       740\n",
        "        pos       0.71      0.61      0.66       760\n",
        "\n",
        "avg / total       0.68      0.68      0.68      1500\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[552 188]\n",
        " [297 463]]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Conjecture about the errors:\n",
      "We chose to investigate some errors using LinearSVC since for it gave the best predictions for us (with around 81% accuracy) while still having room for improvement."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use LinearSVC to predict classes\n",
      "classifier = LinearSVC(C=1001)\n",
      "\n",
      "classifier.fit(XTrain, y_test)\n",
      "y_predicted = classifier.predict(XTest)\n",
      "\n",
      "false_positive_index = -1\n",
      "false_negative_index = -1\n",
      "for i in range(len(y_train)):\n",
      "    if y_train[i] == 0 and y_predicted[i] == 1 and false_positive_index == -1:\n",
      "        false_positive_index = i\n",
      "    if y_train[i] == 1 and y_predicted[i] == 0 and false_negative_index == -1:\n",
      "        false_negative_index = i\n",
      "    if false_positive_index > 0 and false_negative_index > 0:\n",
      "        break\n",
      "\n",
      "print 'Example of false positive:'\n",
      "print docs_train[false_positive_index]\n",
      "print\n",
      "\n",
      "print 'Example of false negative:'\n",
      "print docs_train[false_negative_index]\n",
      "print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Example of false positive:\n",
        "_dirty_work_ has a premise of deliciously mean-spirited potential . \n",
        "mitch weaver ( norm macdonald ) and his lifelong best friend sam mckenna ( artie lange ) are losers in life : they were constantly picked on in school , and now they cannot hold regular jobs . \n",
        "but as the trailer goes , \" there is one thing mitch weaver is good at--revenge . \" \n",
        "so he and sam parlay their unmatched skill in getting-even schemes into a marketable revenge-for-hire business called dirty work inc . \n",
        "this should be the groundwork for a wonderfully wicked black comedy , but for a film called _dirty_work_ , what ensues is rather clean of spirit . \n",
        "in fact , what makes mitch and sam start up their business is not a giddy desire to give bullies a taste of their own medicine , but rather a more sappy reason : sam's father ( jack warden ) needs a heart transplant , and in order for him to move at the top of the recipient list , his compulsively betting doctor ( chevy chase ) asks the guys for $50 , 000 to pay off his bookie . \n",
        "so for all the scheming that goes on , beneath every underhanded plot is--gasp ! --a \n",
        "heart , which undercuts the inherent nastiness of the premise . \n",
        "not that there isn't a lot of nastiness on display--there is , but of a different sort . \n",
        "there are frequent sexual references , most prominently in the form of prostitutes and sam's impotent father's ongoing lust for them . \n",
        "and for a film rated pg-13 , director bob saget ( yes , that bob saget , of _full_house_ and _america's_funniest_home_videos_ fame ) and writers frank sebastiano , fred wolf , and macdonald himself , stretch the boundaries of good taste rather far--arguably a bit too much so ( was not one , but two separate instances of sodomy between animals really necessary ? ) . \n",
        "but the issue , of course , is not so much of taste as it is humor--as in , is it funny or not ? \n",
        "the answer is a resounding no . \n",
        "it's not that macdonald isn't a funny guy . \n",
        "he was one of the more consistently funny performers on _saturday_night_live_ before his much-talked-about firing , and his dry brand of smartass wit translates well to the big screen ; it also doesn't hurt that he's a natural , likable screen presence . \n",
        "he is able to give some of his lines a nice acid touch , but , for the most part , the oneliners , as written , are flat , and the broad slapstick gags just don't work ( one running gag has him being literally tossed out of buildings--a real riot ) . \n",
        "still , macdonald's few shining moments are just about the only moments the film has . \n",
        "the late chris farley , as hysterical as he ever was , is amusing in a cameo role , but , as a whole , the supporting players are amateurish and seemingly free from any directorial guidance . \n",
        "saget tries to juice up the proceedings with kitschy cameos by gary coleman , adam sandler , and john goodman , but their minimal novelty value cannot prevent _dirty_work_ from sputtering to the end of its brief 81-minute running time . \n",
        "the film closes on a sad note of desperation , an indulgent reel of outtakes from which only those involved in the production would derive any amusement . \n",
        "come to think of it , i cannot imagine anyone but those involved in the production to find much amusement in the entirety of _dirty_work_ . \n",
        "\n",
        "\n",
        "Example of false negative:\n",
        "usually when a blockbuster comes out , it's loaded with effects , stars , bad scripts , and plenty of action . \n",
        "mystery men may contain an all-star cast , and efects , but the clever script and characters are what really works , which is rare to see this year . \n",
        "the film is based upon the comic book series \" the flaming carrot \" by bob burden , in which 3 wanna be super heroes try and fight crime , only to be out done by the real hero of champion city , captain amazing ( greg kinnear ) . \n",
        "things go a little haywire , when the sinister casanova frankenstein ( geoffrey rush ) is released into the city , where he captures captain amazing , and plans to wreak havoc upon champion city . \n",
        "well , the trio decide to take matters in their own hands , by saving the city , but first they need some assitance . \n",
        "this is where the film takes a turn for the better . \n",
        "in the beggining , there were only 3 wanna be heroes . \n",
        " \" blue raja ( hank azaria ) , \" mr . furious ( ben stiller ) and \" the shoveller ( william h . macy ) . \n",
        "sure they were enterataining , but their acts grew old fast . \n",
        "that is until they aquire \" invisible boy \" ( kel mitchell ) , and \" the bowler \" ( janeane garafalo ) and \" mr . splein \" ( paul reubens ) , 2 of which rescue the film from becoming a disastorous mess . \n",
        "thankfully , the original 3 heroes become amusing , with some support of reuben and garfalo on screen . \n",
        "the whole premise is rather ridiculous , but packs a few punches to keep interest . \n",
        "for one , the film is considerably clever . \n",
        "it literally pokes fun at super hero films , like batman and robin , superman etc . in fact , many scenes are similar to batman and robin , including the opening sequence , only altered in a humorous and superior way . \n",
        "a part of the cleverness comes from the cast . \n",
        "sometimes a film with such talent is overblown , but the acting is what keeps it alive here . \n",
        "while azaria and macy were enteratining , 2 characters really stood out . \n",
        "one was paul reuben . \n",
        "no matter how disgusting or revolting \" mr . splein \" may be , you still can't help but laugh . \n",
        "it' so incredibly moronic , it's just a riot watching reuben relieve himself of bodily functions . \n",
        "janeane garafalo also was an interesting character . \n",
        "she seemed to be the most outgoing and convincing character on screem , due to her enthusiasm , that kept the film flowing . \n",
        "men is worth seeing alone , for those 2 troubled heroes . \n",
        "on the downside , a few of the heroes and especially the villain never really lift off . \n",
        "kel mitchell and geoffrey rush , were both utterly useless . \n",
        "their parts were so limited , they'd be lucky at all to be on screen for more than 20 minutes . \n",
        "ben stiller too was wasted , mostly because of his unlikeable power and dialogue . \n",
        "none of these characters get a rise out of anybody , but happily they are lost in the charming flow of the film . \n",
        "as far as the budget goes , it was wisely spent on the cast , not the effects . \n",
        "while the set designs and action all look nice , i'm glad there was a seperate aspect , that the film focused on , and for that i applaud . \n",
        "slow at times , and rather pointless , mystery men still delivers . \n",
        "it forgets about money making , because it's not likely to make a bundle like it's proceeders , and that's what works . \n",
        "stupid ? \n",
        "maybe , but for once i'm not disappointed . \n",
        "no one expected an intelligent film , but you get a film thats wit captures your attention and makes you forget this miserable year . \n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*------------------------\n",
      "\n",
      "#Problem 4: Open Ended Question:  Finding the right plot"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Can you find a two dimensional plot in which the positive and negative reviews are separated?\n",
      "    * This problem is hard since you will likely have thousands of features for review, and you will need to transform these thousands of features into just two numbers (so that you can make a 2D plot).\n",
      "* Note, I was not able to find such a plot myself!\n",
      "    * So, this problem is about **trying** but perhaps **not necessarily succeeding**!\n",
      "* I tried two things, neither of which worked very well.\n",
      "    * I first plotted the length of the review versus the number of features we compute that are in that review\n",
      "    * Second I used Principle Component Analysis on a subset of the features.\n",
      "* Can you do better than I did!?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_selection import SelectKBest\n",
      "from sklearn.feature_selection import chi2\n",
      "import matplotlib.pylab as py\n",
      "\n",
      "tfidf_vectorizer = TfidfVectorizer(min_df=2, max_df=0.86, ngram_range=(1, 3))\n",
      "\n",
      "# train on docs_test and build XTrain and XTest\n",
      "XTrain = tfidf_vectorizer.fit_transform(docs_test)\n",
      "XTest = tfidf_vectorizer.transform(docs_train)\n",
      "\n",
      "features = tfidf_vectorizer.get_feature_names()\n",
      "\n",
      "selector = SelectKBest(chi2, k=2)\n",
      "X_train = selector.fit_transform(XTrain, y_test)\n",
      "X_test = selector.transform(XTest)\n",
      "\n",
      "support = selector.get_support()\n",
      "print 'The most important features are:'\n",
      "for i in range(len(support)):\n",
      "    if support[i]:\n",
      "        print features[i]\n",
      "print\n",
      "\n",
      "X = X_train.toarray()\n",
      "Xte = X_test.toarray()\n",
      "\n",
      "# negative\n",
      "py.plot(X[y_test==0,0], X[y_test==0,1],'r.')\n",
      "py.plot(Xte[y_train==0,0], Xte[y_train==0,1],'r.')\n",
      "# positive\n",
      "py.plot(X[y_test==1,0], X[y_test==1,1],'g.')\n",
      "py.plot(Xte[y_train==1,0], Xte[y_train==1,1],'g.')\n",
      "py.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The most important features are:\n",
        "bad\n",
        "flynt\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0xbaaed10>"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*-----------------\n",
      "# Done\n",
      "\n",
      "All set! \n",
      "\n",
      "** What do you need to submit?**\n",
      "\n",
      "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
      "\n",
      "\n",
      "* **PPT Slides**: please prepare PPT slides (for 10 minutes' talk) to present about the case study . We will ask two teams which are randomly selected to present their case studies in class for this case study. \n",
      "\n",
      "* ** Report**: please prepare a report (less than 10 pages) to report what you found in the data.\n",
      "    * How did you analyse the data?\n",
      "    * What did you find in the data? \n",
      "    * What classifier worked better?\n",
      "    * Which parameters worked better?\n",
      "    * Did you come up with a good plot?\n",
      "\n",
      "     (please include figures or tables in the report, but no source code)\n",
      "\n",
      "Please compress all the files in a zipped file.\n",
      "\n",
      "\n",
      "** How to submit: **\n",
      "\n",
      "        Send an email to rcpaffenroth@wpi.edu with the subject: \"[DS501_f14a] Case study 3\"."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}