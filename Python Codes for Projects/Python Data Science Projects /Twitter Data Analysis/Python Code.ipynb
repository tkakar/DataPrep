{
 "metadata": {
  "name": "",
  "signature": "sha256:f7d4a4fb5a4fb9a0358933d0f9e104a4735c38aa099ca64d49631cd0bd12ba98"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Case Study 1 : Collecting Data from Twitter\n",
      "\n",
      "** Due Date: Sep. 21, 11:59PM**\n",
      "\n",
      "*------------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**TEAM Members:** Please EDIT this cell and add the names of all the team members in your team\n",
      "\n",
      "    Chong Zhou (Andy)\n",
      "    \n",
      "    Diana Batista\n",
      "    \n",
      "    Marcus Moyses\n",
      "    \n",
      "    Tabassum Kakar\n",
      "    "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Problem 1: Sampling Twitter Data with Streaming API about a certain topic"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Select a topic that you are interested in, for example, \"WPI\" or \"Lady Gaga\"\n",
      "* Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million.\n",
      "* Store the tweets you downloaded into a local file (txt file or json file) "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "#--------------------- Connecting to the API ------------------------ #\n",
      "\n",
      "import twitter\n",
      "\n",
      "# Define a Function to Login Twitter API\n",
      "def oauth_login():\n",
      "    # Go to http://twitter.com/apps/new to create an app and get values\n",
      "    # for these credentials that you'll need to provide in place of these\n",
      "    # empty string values that are defined as placeholders.\n",
      "    # See https://dev.twitter.com/docs/auth/oauth for more information \n",
      "    # on Twitter's OAuth implementation.\n",
      "    \n",
      "    CONSUMER_KEY = 'pRxit15SVFB2TFadBOhVHBvVV'\n",
      "    CONSUMER_SECRET ='fjOv5yc7eZkQeWmEVL88r7zGP8KouqIAsdW7y3BuiyM9gysMKl'\n",
      "    OAUTH_TOKEN = '1405865372-MqBzaSd6c6x9JbFHbAkHI2O1PSNI0p5bgKWWX2N'\n",
      "    OAUTH_TOKEN_SECRET = 'FXoYNvFrL36qVllwcXmTtLwlu9yRPfv8BUqivMCG2Ed7w'\n",
      "    \n",
      "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
      "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
      "    \n",
      "    twitter_api = twitter.Twitter(auth=auth)\n",
      "    return twitter_api\n",
      "\n",
      "#------------------------ Searching Tweets for the favorite topic \"DataScience ------------\"\n",
      "\n",
      "# term to query\n",
      "q = 'drugs'\n",
      "\n",
      "def twitter_search(twitter_api, q, max_results=1000000, **kw):\n",
      "    search_results = twitter_api.search.tweets(q=q, count=100, **kw)\n",
      "    \n",
      "    statuses = search_results['statuses']\n",
      "    \n",
      "    for _ in range(10000):\n",
      "        try:\n",
      "            next_results = search_results['search_metadata']['next_results']\n",
      "        except KeyError, e: # no more results when next_results doesn't exist\n",
      "            break\n",
      "        \n",
      "        # create dictionary from next_results\n",
      "        kwargs = dict([kv.split('=') for kv in next_results[1:].split('&')])\n",
      "        \n",
      "        search_results = twitter_api.search.tweets(**kwargs)\n",
      "        statuses += search_results['statuses']\n",
      "        \n",
      "        # check if we already have max_results\n",
      "        if len(statuses) > max_results:\n",
      "            break\n",
      "        \n",
      "    return statuses\n",
      "\n",
      "import io, json\n",
      "\n",
      "def save_json(filename, data):\n",
      "    with io.open(filename, 'w', encoding='utf-8') as f:\n",
      "        f.write(unicode(json.dumps(data, ensure_ascii=False)))\n",
      "\n",
      "# warn user when search starts\n",
      "print 'Searching for tweets...'\n",
      "\n",
      "results = twitter_search(oauth_login(), q)\n",
      "\n",
      "# warn user when search finishes\n",
      "print '...done'\n",
      "\n",
      "filename = 'case_study_1.json'\n",
      "\n",
      "# warn about writing to file\n",
      "print 'Saving tweets to file ' + filename + '...'\n",
      "\n",
      "# saves tweets\n",
      "save_json(filename, results)\n",
      "\n",
      "# warn user that writing is complete\n",
      "print '...done'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Searching for tweets...\n"
       ]
      },
      {
       "ename": "TwitterHTTPError",
       "evalue": "Twitter sent status 401 for URL: 1.1/search/tweets.json using parameters: (count=100&oauth_consumer_key=pRxit15SVFB2TFadBOhVHBvVV&oauth_nonce=2941310138090624847&oauth_signature_method=HMAC-SHA1&oauth_timestamp=1441907834&oauth_token=1405865372-MqBzaSd6c6x9JbFHbAkHI2O1PSNI0p5bgKWWX2N&oauth_version=1.0&q=drugs&oauth_signature=YfENpdQzLI8DIwPrCaBsiCJZIp4%3D)\ndetails: {\"errors\":[{\"code\":32,\"message\":\"Could not authenticate you.\"}]}",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTwitterHTTPError\u001b[0m                          Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-a6d94f357aa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Searching for tweets...'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwitter_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moauth_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# warn user when search finishes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-1-a6d94f357aa2>\u001b[0m in \u001b[0;36mtwitter_search\u001b[0;34m(twitter_api, q, max_results, **kw)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtwitter_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwitter_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0msearch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwitter_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mstatuses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'statuses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/tabassum/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/twitter/api.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muriBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/tabassum/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/twitter/api.pyc\u001b[0m in \u001b[0;36m_handle_response\u001b[0;34m(self, req, uri, arg_data, _timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTwitterHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTwitterHTTPError\u001b[0m: Twitter sent status 401 for URL: 1.1/search/tweets.json using parameters: (count=100&oauth_consumer_key=pRxit15SVFB2TFadBOhVHBvVV&oauth_nonce=2941310138090624847&oauth_signature_method=HMAC-SHA1&oauth_timestamp=1441907834&oauth_token=1405865372-MqBzaSd6c6x9JbFHbAkHI2O1PSNI0p5bgKWWX2N&oauth_version=1.0&q=drugs&oauth_signature=YfENpdQzLI8DIwPrCaBsiCJZIp4%3D)\ndetails: {\"errors\":[{\"code\":32,\"message\":\"Could not authenticate you.\"}]}"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Report some statistics about the tweets you collected\n",
      "* The topic of interest: \n",
      "* The total number of tweets collected: "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Problem 2: Analyzing Tweets and Tweet Entities with Frequency Analysis\n",
      "\n",
      "**1. Word Count:** \n",
      "* Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets. \n",
      "* Plot a table of the top 30 words with their counts"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#--------------------- To compute the word frequencies in the gathered tweets --------------------#\n",
      "\n",
      "import io, json\n",
      "from collections import Counter\n",
      "\n",
      "# defining function to load file\n",
      "def load_json(filename):\n",
      "    with io.open(filename, encoding='utf-8') as f:\n",
      "        return json.loads(f.read())\n",
      "\n",
      "# read tweets from file\n",
      "results = load_json('case_study_1.json')\n",
      "\n",
      "def get_common_words(statuses):\n",
      "\n",
      "    # create a flat list of all words\n",
      "    words = [ w \n",
      "          for s in statuses\n",
      "              for w in s['text'].split() ]\n",
      "    \n",
      "    # return top 30 words\n",
      "    return Counter(words).most_common(30)\n",
      "\n",
      "from prettytable import PrettyTable\n",
      "\n",
      "# create table\n",
      "pt = PrettyTable(field_names=['Word', 'Count'])\n",
      "\n",
      "[ pt.add_row(kv) for kv in get_common_words(results) ]\n",
      "pt.align['Word'], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
      "print pt\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "+--------------+-------+\n",
        "| Word         | Count |\n",
        "+--------------+-------+\n",
        "| RT           |  2290 |\n",
        "| #datascience |  1706 |\n",
        "| #DataScience |  1313 |\n",
        "| of           |   974 |\n",
        "| Big          |   816 |\n",
        "| to           |   792 |\n",
        "| the          |   766 |\n",
        "| What         |   765 |\n",
        "| Is           |   734 |\n",
        "| #bigdata     |   709 |\n",
        "| Data         |   690 |\n",
        "| #BigData     |   681 |\n",
        "| Data?        |   588 |\n",
        "| and          |   537 |\n",
        "| in           |   502 |\n",
        "| a            |   490 |\n",
        "| for          |   476 |\n",
        "| is           |   440 |\n",
        "| -            |   372 |\n",
        "| on           |   364 |\n",
        "| data         |   340 |\n",
        "| via          |   332 |\n",
        "| at           |   302 |\n",
        "| &amp;        |   290 |\n",
        "| @KirkDBorne: |   289 |\n",
        "| The          |   286 |\n",
        "| with         |   268 |\n",
        "| #Analytics   |   241 |\n",
        "| by           |   235 |\n",
        "| from         |   229 |\n",
        "+--------------+-------+\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**2. Find the most popular tweets in your collection of tweets**\n",
      "\n",
      "Please plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#---------------------- extracting most popular tweets from the collected tweets -----------------------#\n",
      "\n",
      "def get_most_popular(statuses):\n",
      "    ids = set()\n",
      "    popular = []\n",
      "    for status in statuses:\n",
      "        if status.has_key('retweeted_status'):  # most popular tweets are the tweets having retweeted_statuses true\n",
      "            # avoid adding duplicates\n",
      "            if status['retweeted_status']['id'] not in ids:\n",
      "                ids.add(status['retweeted_status']['id'])\n",
      "                popular += [(status['retweet_count'], status['retweeted_status']['user']['screen_name'], status['text'])]\n",
      "    return popular\n",
      "\n",
      "# putting the popular tweets in the table\n",
      "pt = PrettyTable(field_names=['Count', 'Screen Name', 'Text'])\n",
      "[ pt.add_row(row) for row in sorted(get_most_popular(results), reverse=True)[:10] ] # for top 10 tweets\n",
      "pt.max_width['Text'] = 80\n",
      "pt.align= 'l'\n",
      "print pt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "+-------+-----------------+----------------------------------------------------------------------------------+\n",
        "| Count | Screen Name     | Text                                                                             |\n",
        "+-------+-----------------+----------------------------------------------------------------------------------+\n",
        "| 445   | TEDTalks        | RT @TEDTalks: \"Mathematics is not just solving for x; it's also figuring out     |\n",
        "|       |                 | why.\" http://t.co/XyrulLO4JR                                                     |\n",
        "| 417   | yext            | RT @yext: The future of local marketing is Geomarketing. @gsterling teaches      |\n",
        "|       |                 | marketers to stay ahead. http://t.co/D4oN20fZiS https://t.co/Or\u2026                 |\n",
        "| 213   | TEDTalks        | RT @TEDTalks: \"The greater our proficiency, the more clearly we see that we      |\n",
        "|       |                 | don't know all we thought we did.\" http://t.co/UiV0SYYw28                        |\n",
        "| 138   | randal_olson    | RT @randal_olson: For all the folks stating correlation != causation today:      |\n",
        "|       |                 | http://t.co/Z7w3jJAccQ #datascience http://t.co/L2ptSPfWVa                       |\n",
        "| 117   | AnalyticsChap   | RT @AnalyticsChap: Ahh, so Data Scientists look like Buddy Holly? But seriously, |\n",
        "|       |                 | this is a good infographic #datascience #data http://t.co/\u2026                      |\n",
        "| 106   | cyrillerossant  | RT @cyrillerossant: IPython Cookbook completed, at last! 15 months of effort.    |\n",
        "|       |                 | 500-pages book released next week. http://t.co/PZeGy3OZjL #py\u2026                   |\n",
        "| 87    | profjsb         | RT @profjsb: Push back on #datascience is like the mathematician push back on    |\n",
        "|       |                 | nascent computer science back in the day- @craragon http://t.\u2026                   |\n",
        "| 49    | MSFTResearch    | RT @MSFTResearch: .@erichorvitz's #KDD2014 keynote slides on using #datascience  |\n",
        "|       |                 | for social good #MLatMSFT http://t.co/ljvnjvplRp http://t.c\u2026                     |\n",
        "| 35    | ManeeshJuneja   | RT @ManeeshJuneja: #DataScience skillset explained in an infographic             |\n",
        "|       |                 | http://t.co/M85bqOiJcZ via @MktngDistillery #bigdata http://t.co/UNW2e\u2026          |\n",
        "| 35    | DataScienceCtrl | RT @DataScienceCtrl: RT @KirkDBorne: And now from Gartner &gt; The #DataScience  |\n",
        "|       |                 | Venn Diagram Revisited: http://t.co/zhVEAQC31X http://t.co/UUy\u2026                  |\n",
        "+-------+-----------------+----------------------------------------------------------------------------------+\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**3. Find the most popular Tweet Entities in your collection of tweets**\n",
      "\n",
      "Please plot a table of the top 10 hashtags, top 10 user mentions that are the most popular in your collection of tweets."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#----------------------  extracting top 10 hasstags and users mentioned in the collected most popular tweets   ------------------------ #\n",
      "\n",
      "\n",
      "def extract_tweet_entities(statuses):\n",
      "    \n",
      "    #  if there are statuses just return empty fields\n",
      "\n",
      "\n",
      "    if len(statuses) == 0:\n",
      "        return [], [], [], [], []\n",
      "    \n",
      "    screen_names = [ user_mention['screen_name'] \n",
      "                         for status in statuses\n",
      "                            for user_mention in status['entities']['user_mentions'] ]\n",
      "    \n",
      "    hashtags = [ hashtag['text'] \n",
      "                     for status in statuses \n",
      "                        for hashtag in status['entities']['hashtags'] ]\n",
      "\n",
      "    urls = [ url['expanded_url'] \n",
      "                     for status in statuses \n",
      "                        for url in status['entities']['urls'] ]\n",
      "    \n",
      "    symbols = [ symbol['text']\n",
      "                   for status in statuses\n",
      "                       for symbol in status['entities']['symbols'] ]\n",
      "               \n",
      "    # In some circumstances (such as search results), the media entity\n",
      "    # may not appear\n",
      "    if status['entities'].has_key('media'): \n",
      "        media = [ media['url'] \n",
      "                         for status in statuses  \n",
      "                            for media in status['entities']['media'] ]\n",
      "    else:\n",
      "        media = []\n",
      "\n",
      "    return screen_names, hashtags, urls, media, symbols\n",
      "\n",
      "def get_common_hashtags(statuses):\n",
      "\n",
      "    # Create a flat list of all hashtags\n",
      "    hashtags = [ h.lower()\n",
      "                    for status in statuses\n",
      "                        for h in extract_tweet_entities([status])[1]\n",
      "                ]\n",
      "\n",
      "    c = Counter(hashtags).most_common(10)\n",
      "\n",
      "    # Compute frequencies\n",
      "    return [ (k,v) \n",
      "             for (k,v) in c\n",
      "           ]\n",
      "\n",
      "def get_common_user_mentions(statuses):\n",
      "\n",
      "    # Create a flat list of all user mentions\n",
      "    mentions = [ m\n",
      "                    for status in statuses\n",
      "                        for m in extract_tweet_entities([status])[0]\n",
      "                ]\n",
      "\n",
      "    c = Counter(mentions).most_common(10)\n",
      "\n",
      "    # Compute frequencies\n",
      "    return [ (k,v) \n",
      "             for (k,v) in c\n",
      "           ]\n",
      "\n",
      "pt = PrettyTable(field_names=['Hashtag', 'Count']) \n",
      "[ pt.add_row(kv) for kv in get_common_hashtags(results) ]\n",
      "pt.align['Hashtag'], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
      "print pt\n",
      "\n",
      "pt = PrettyTable(field_names=['User Mention', 'Count']) \n",
      "[ pt.add_row(kv) for kv in get_common_user_mentions(results) ]\n",
      "pt.align['User Mentions'], pt.align['Count'] = 'l', 'r' # Set column alignment\n",
      "print pt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "+-----------------+-------+\n",
        "| Hashtag         | Count |\n",
        "+-----------------+-------+\n",
        "| datascience     |  3510 |\n",
        "| bigdata         |  1742 |\n",
        "| analytics       |   523 |\n",
        "| newyork         |   191 |\n",
        "| data            |   179 |\n",
        "| science         |   177 |\n",
        "| python          |   164 |\n",
        "| machinelearning |   154 |\n",
        "| statistics      |   121 |\n",
        "| rstats          |   115 |\n",
        "+-----------------+-------+\n",
        "+----------------+-------+\n",
        "|  User Mention  | Count |\n",
        "+----------------+-------+\n",
        "|   KirkDBorne   |   307 |\n",
        "| AngelaZutavern |   113 |\n",
        "| cyrillerossant |   102 |\n",
        "|  DiegoKuonen   |    73 |\n",
        "|  mjcavaretta   |    62 |\n",
        "|    smacconf    |    56 |\n",
        "|   bobehayes    |    52 |\n",
        "|   kdnuggets    |    52 |\n",
        "|   tonyojeda3   |    48 |\n",
        "|   BigDataGal   |    45 |\n",
        "+----------------+-------+"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*------------------------\n",
      "\n",
      "#Problem 3: Getting \"All\" friends and \"All\" followers of a popular user in twitter\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
      "* Get the list of all friends and all followers of the twitter user.\n",
      "* Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
      "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#------------------------------------   Popular twitter User with many followers   --------------------#\n",
      "\n",
      "\n",
      "from functools import partial\n",
      "from sys import maxint\n",
      "import sys\n",
      "import time\n",
      "from urllib2 import URLError\n",
      "from httplib import BadStatusLine\n",
      "import json\n",
      "import twitter\n",
      "import json\n",
      "from prettytable import PrettyTable\n",
      "\n",
      "#the function which make sure the connection stable and if it crashes, show some info about what happened\n",
      "def make_twitter_request(twitter_api_func, max_errors=10, *args, **kw): \n",
      "    \n",
      "    # A nested helper function that handles common HTTPErrors. Return an updated\n",
      "    # value for wait_period if the problem is a 500 level error. Block until the\n",
      "    # rate limit is reset if it's a rate limiting issue (429 error). Returns None\n",
      "    # for 401 and 404 errors, which requires special handling by the caller.\n",
      "    def handle_twitter_http_error(e, wait_period=2, sleep_when_rate_limited=True):\n",
      "    \n",
      "        if wait_period > 3600: # Seconds\n",
      "            print >> sys.stderr, 'Too many retries. Quitting.'\n",
      "            raise e\n",
      "    \n",
      "        # See https://dev.twitter.com/docs/error-codes-responses for common codes\n",
      "    \n",
      "        if e.e.code == 401:\n",
      "            print >> sys.stderr, 'Encountered 401 Error (Not Authorized)'\n",
      "            return None\n",
      "        elif e.e.code == 404:\n",
      "            print >> sys.stderr, 'Encountered 404 Error (Not Found)'\n",
      "            return None\n",
      "        elif e.e.code == 429: \n",
      "            print >> sys.stderr, 'Encountered 429 Error (Rate Limit Exceeded)'\n",
      "            if sleep_when_rate_limited:\n",
      "                print >> sys.stderr, \"Retrying in 15 minutes...ZzZ...\"\n",
      "                sys.stderr.flush()\n",
      "                time.sleep(60*15 + 5)\n",
      "                print >> sys.stderr, '...ZzZ...Awake now and trying again.'\n",
      "                return 2\n",
      "            else:\n",
      "                raise e # Caller must handle the rate limiting issue\n",
      "        elif e.e.code in (500, 502, 503, 504):\n",
      "            print >> sys.stderr, 'Encountered %i Error. Retrying in %i seconds' % \\\n",
      "                (e.e.code, wait_period)\n",
      "            time.sleep(wait_period)\n",
      "            wait_period *= 1.5\n",
      "            return wait_period\n",
      "        else:\n",
      "            raise e\n",
      "\n",
      "    # End of nested helper function\n",
      "    \n",
      "    wait_period = 2 \n",
      "    error_count = 0 \n",
      "\n",
      "    while True:\n",
      "        try:\n",
      "            return twitter_api_func(*args, **kw)\n",
      "        except twitter.api.TwitterHTTPError, e:\n",
      "            error_count = 0 \n",
      "            wait_period = handle_twitter_http_error(e, wait_period)\n",
      "            if wait_period is None:\n",
      "                return\n",
      "        except URLError, e:\n",
      "            error_count += 1\n",
      "            time.sleep(wait_period)\n",
      "            wait_period *= 1.5\n",
      "            print >> sys.stderr, \"URLError encountered. Continuing.\"\n",
      "            if error_count > max_errors:\n",
      "                print >> sys.stderr, \"Too many consecutive errors...bailing out.\"\n",
      "                raise\n",
      "        except BadStatusLine, e:\n",
      "            error_count += 1\n",
      "            time.sleep(wait_period)\n",
      "            wait_period *= 1.5\n",
      "            print >> sys.stderr, \"BadStatusLine encountered. Continuing.\"\n",
      "            if error_count > max_errors:\n",
      "                print >> sys.stderr, \"Too many consecutive errors...bailing out.\"\n",
      "                raise\n",
      "\n",
      "#This is the function that use user_id or screen_name to get user's friends \n",
      "def get_friends_followers_ids(twitter_api, screen_name=None, user_id=None,\n",
      "                              friends_limit=maxint, followers_limit=maxint):\n",
      "    \n",
      "    # Must have either screen_name or user_id (logical xor)\n",
      "    assert (screen_name != None) != (user_id != None), \\\n",
      "    \"Must have screen_name or user_id, but not both\"\n",
      "    \n",
      "    get_friends_ids = partial(make_twitter_request, twitter_api.friends.ids, \n",
      "                              count=5000)\n",
      "    get_followers_ids = partial(make_twitter_request, twitter_api.followers.ids, \n",
      "                                count=5000)\n",
      "\n",
      "    friends_ids, followers_ids = [], []\n",
      "    \n",
      "    for twitter_api_func, limit, ids, label in [\n",
      "                    [get_friends_ids, friends_limit, friends_ids, \"friends\"], \n",
      "                    [get_followers_ids, followers_limit, followers_ids, \"followers\"]\n",
      "                ]:\n",
      "        \n",
      "        if limit == 0: continue\n",
      "        \n",
      "        cursor = -1\n",
      "        while cursor != 0:\n",
      "        \n",
      "            # Use make_twitter_request via the partially bound callable...\n",
      "            if screen_name: \n",
      "                response = twitter_api_func(screen_name=screen_name, cursor=cursor)\n",
      "            else: # user_id\n",
      "                response = twitter_api_func(user_id=user_id, cursor=cursor)\n",
      "\n",
      "            if response is not None:\n",
      "                ids += response['ids']\n",
      "                cursor = response['next_cursor']\n",
      "        \n",
      "            print >> sys.stderr, 'Fetched {0} total {1} ids for {2}'.format(len(ids), \n",
      "                                                    label, (user_id or screen_name))\n",
      "        \n",
      "            if len(ids) >= limit or response is None:\n",
      "                break\n",
      "\n",
      "    # return searching result\n",
      "    return friends_ids[0:friends_limit], followers_ids[0:followers_limit]\n",
      "\n",
      "#the function below is to get the user info with the intersection user_id\n",
      "def get_user_profile(twitter_api, screen_names=None, user_ids=None):\n",
      "   \n",
      "    # Must have either screen_name or user_id (logical xor)\n",
      "    assert (screen_names != None) != (user_ids != None), \\\n",
      "    \"Must have screen_names or user_ids, but not both\"\n",
      "    \n",
      "    items_to_info = {}\n",
      "\n",
      "    items = screen_names or user_ids\n",
      "    \n",
      "    while len(items) > 0:\n",
      "        \n",
      "        items_str = ','.join([str(item) for item in items[:100]])\n",
      "        items = items[100:]\n",
      "\n",
      "        if screen_names:\n",
      "            response = make_twitter_request(twitter_api.users.lookup, \n",
      "                                            screen_name=items_str)\n",
      "        else: # user_ids\n",
      "            response = make_twitter_request(twitter_api.users.lookup, \n",
      "                                            user_id=items_str)\n",
      "    \n",
      "        for user_info in response:\n",
      "            if screen_names:\n",
      "                items_to_info[user_info['screen_name']] = user_info\n",
      "            else: # user_ids\n",
      "                items_to_info[user_info['id']] = user_info\n",
      "\n",
      "    return items_to_info\n",
      "\n",
      "# call\n",
      "twitter_api = oauth_login()\n",
      "#get friends and followers\n",
      "friends_ids, followers_ids = get_friends_followers_ids(twitter_api, \n",
      "                                                       screen_name=\"Randy_Couture\", \n",
      "                                                       #user_id=\"50539213\",\n",
      "                                                       friends_limit=5000, \n",
      "                                                       followers_limit=5000)\n",
      "\n",
      "#show result, it shows that randy is really famous person who has large amount of followers\n",
      "#print friends_ids\n",
      "#print followers_ids\n",
      "\n",
      "#----- plotting the top 10 followeres and friends in the table ------#\n",
      "\n",
      "friends_ids20=friends_ids[0:19]\n",
      "#print friends_ids\n",
      "followers_ids20=followers_ids[0:19]\n",
      "\n",
      "friends_profile=get_user_profile(twitter_api,user_ids=friends_ids20)\n",
      "followers_profile=get_user_profile(twitter_api,user_ids=followers_ids20)\n",
      "\n",
      "friends_screen_name=[]\n",
      "followers_screen_name=[]\n",
      "\n",
      "for user_profile in friends_profile:\n",
      "     #print friends_profile[user_profile][\"screen_name\"]\n",
      "     friends_screen_name.append(friends_profile[user_profile][\"screen_name\"].encode('utf-8'))\n",
      "\n",
      "for user_profile in followers_profile:\n",
      "     #print followers_profile[user_profile][\"screen_name\"]\n",
      "     followers_screen_name.append(followers_profile[user_profile][\"screen_name\"].encode('utf-8')) \n",
      "\n",
      "friends_result_table=PrettyTable()\n",
      "friends_result_table.padding_width = 2\n",
      "\n",
      "#add column is much easier than add row\n",
      "friends_result_table.add_column(\"User_id\",friends_ids20)\n",
      "friends_result_table.add_column(\"Screen_name\",friends_screen_name)\n",
      "print \"  Friends Ids and Screen Names\"\n",
      "print friends_result_table \n",
      "\n",
      "print\n",
      "\n",
      "followers_result_table=PrettyTable()\n",
      "followers_result_table.padding_width = 2\n",
      "\n",
      "#add column is much easier than add row\n",
      "followers_result_table.add_column(\"User_id\",followers_ids20)\n",
      "followers_result_table.add_column(\"Screen_name\",followers_screen_name)\n",
      "print \"  Followers Ids and Screen Names\"\n",
      "print followers_result_table \n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Fetched 268 total friends ids for Randy_Couture\n",
        "Fetched 5000 total followers ids for Randy_Couture"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Friends Ids and Screen Names\n",
        "+--------------+-------------------+\n",
        "|   User_id    |    Screen_name    |\n",
        "+--------------+-------------------+\n",
        "|  120943272   |     JimCarrey     |\n",
        "|  186344612   |       JRsBBQ      |\n",
        "|   34212917   |   TheLinaCarollo  |\n",
        "|  1165450428  |      RealDDP      |\n",
        "|  887496402   |      ALaForce     |\n",
        "|   86868062   |    ErinAndrews    |\n",
        "|   89556802   |       TheRue      |\n",
        "|   76856486   |     cabrasted     |\n",
        "|  1158861247  |  Followtheblonde  |\n",
        "|  505219769   |  privatetraining  |\n",
        "|   20019468   |    jeffshearer3   |\n",
        "|   31293110   |      dolvett      |\n",
        "|   29255539   |  Karina_Smirnoff  |\n",
        "|  150151257   |   CHRIS_Daughtry  |\n",
        "|  111409543   |     IanZiering    |\n",
        "|   41630638   |  TheDeliverer_32  |\n",
        "|  237611757   |    chillzone95    |\n",
        "|   41838544   |       Uldouz      |\n",
        "|   52551600   |    HISNHERS_TV    |\n",
        "+--------------+-------------------+\n",
        "\n",
        "  Followers Ids and Screen Names\n",
        "+--------------+-------------------+\n",
        "|   User_id    |    Screen_name    |\n",
        "+--------------+-------------------+\n",
        "|  2778081592  |    alden_marano   |\n",
        "|  2603767360  |   AJCrossman6692  |\n",
        "|  2817756103  |      airc1225     |\n",
        "|  2780760186  |     j02010333     |\n",
        "|  2601678608  |     pota_esxt     |\n",
        "|  1969567669  |   scottcampione   |\n",
        "|  1244611405  |  05c799c5d41348f  |\n",
        "|  2755327413  |    _mo_robbins_   |\n",
        "|  210839313   |      1MMANEWS     |\n",
        "|  2820488630  |    JaynaraNeves   |\n",
        "|  2355240157  |    grahambell91   |\n",
        "|  2822246504  |  madisontweaverr  |\n",
        "|  2474884813  |  vegasfantasyvip  |\n",
        "|  494215479   |    fltruckguy77   |\n",
        "|  267326533   |  BarcelosCarlito  |\n",
        "|  2822160120  |    rightcowboy    |\n",
        "|  1849608163  |  damiancaceres30  |\n",
        "|  1942570939  |   EarleyGarrett   |\n",
        "|  2821733490  |  Caggiexforxlife  |\n",
        "+--------------+-------------------+\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## ------------   the codes below are to compute the common Id who are both follower and friends ---------------- ##\n",
      "\n",
      "#json for data storage, prettytable to plot data in tables\n",
      "import json\n",
      "from prettytable import PrettyTable\n",
      "\n",
      "#compute the intersection bewteen followers and friends\n",
      "common=list(set(friends_ids)&set(followers_ids))\n",
      "if common:\n",
      "    print common\n",
      "else:\n",
      "    print\"Empty\"\n",
      "    print \"It's bad! Choose another one...\"\n",
      "print\n",
      "\n",
      "#\n",
      "#get interscetion user profile\n",
      "common_profile = get_user_profile(twitter_api,user_ids=common)\n",
      "\n",
      "#test_use\n",
      "#print json.dumps(common_profile, indent=2)\n",
      "#print\n",
      "\n",
      "print \n",
      "\n",
      "#creat a new list to store the screen_name\n",
      "common_screen_name=[]\n",
      "\n",
      "for user_profile in common_profile:\n",
      "     print common_profile[user_profile][\"screen_name\"]\n",
      "     common_screen_name.append(common_profile[user_profile][\"screen_name\"].encode('utf-8'))\n",
      "\n",
      "\n",
      "print common_screen_name\n",
      "\n",
      "#using pretty table to show the result\n",
      "result_table=PrettyTable()\n",
      "result_table.padding_width = 2\n",
      "\n",
      "#add column is much easier than add row\n",
      "result_table.add_column(\"User_id\",common)\n",
      "result_table.add_column(\"Screen_name\",common_screen_name)\n",
      "\n",
      "print result_table    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[120943272, 34212917]\n",
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ErinAndrews\n",
        "Karina_Smirnoff\n",
        "['ErinAndrews', 'Karina_Smirnoff']\n",
        "+-------------+-------------------+\n",
        "|   User_id   |    Screen_name    |\n",
        "+-------------+-------------------+\n",
        "|  120943272  |    ErinAndrews    |\n",
        "|   34212917  |  Karina_Smirnoff  |\n",
        "+-------------+-------------------+\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*-----------------\n",
      "# Done\n",
      "\n",
      "All set! \n",
      "\n",
      "** What do you need to submit?**\n",
      "\n",
      "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
      "\n",
      "\n",
      "* **PPT Slides**: please prepare PPT slides (for 10 minutes' talk) to present about the case study . We will ask two teams which are randomly selected to present their case studies in class for this case study. \n",
      "\n",
      "* ** Report**: please prepare a report (less than 10 pages) to report what you found in the data.\n",
      "    * What data you collected? \n",
      "    * Why this topic is interesting or important to you? (Motivations)\n",
      "    * How did you analyse the data?\n",
      "    * What did you find in the data? \n",
      " \n",
      "     (please include figures or tables in the report, but no source code)\n",
      "\n",
      "Please compress all the files in a zipped file.\n",
      "\n",
      "\n",
      "** How to submit: **\n",
      "\n",
      "        Send an email to xkong@wpi.edu with the subject: \"[DS501_f14a] Case study 1\"."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}